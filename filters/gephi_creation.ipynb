{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the sentiment has been stored in IG_posts_with_sentiment.json and the overall score has been made as an equal average of taste, presentation, and creativity scores. Field: \"overall_score\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create Gephi bipartite graph (.csv files compatible as nodes and edges in Gephi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All necessary imports\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files created:\n",
      " - influencer_nodes.csv\n",
      " - influencer_edges.csv\n",
      " - restaurant_nodes.csv\n",
      " - restaurant_edges.csv\n"
     ]
    }
   ],
   "source": [
    "# Gephi Creation\n",
    "\n",
    "# First, the primary overview (one-mode projections of bipartite network)\n",
    "\n",
    "with open('../outputs/IG_posts_with_sentiment.json', 'r', encoding='utf-8') as f:\n",
    "    ig_posts = json.load(f)\n",
    "\n",
    "# Initialize sets for nodes \n",
    "influencer_nodes = set()\n",
    "restaurant_nodes = set()\n",
    "\n",
    "# Dictionaries for edge mappings\n",
    "# for influencers: map each restaurant to a set that reviewed it\n",
    "restaurant_to_influencers = {}\n",
    "\n",
    "# for restaurants: map each influencer to the set of restaurants they reviewed\n",
    "influencer_to_restaurants = {}\n",
    "\n",
    "# iterate and fill sets and mappings\n",
    "for post in ig_posts:\n",
    "    influencer = post.get(\"influencerUsername\", \"\").strip()\n",
    "    restaurant = post.get(\"restaurantName\", \"\").strip()\n",
    "    \n",
    "    # skip if no influencer or restaurant\n",
    "    if not influencer or not restaurant:\n",
    "        continue\n",
    "    \n",
    "    # add to sets\n",
    "    influencer_nodes.add(influencer)\n",
    "    restaurant_nodes.add(restaurant)\n",
    "    \n",
    "    # add to mappings\n",
    "    if restaurant not in restaurant_to_influencers:\n",
    "        restaurant_to_influencers[restaurant] = set()\n",
    "    restaurant_to_influencers[restaurant].add(influencer)\n",
    "    \n",
    "    if influencer not in influencer_to_restaurants:\n",
    "        influencer_to_restaurants[influencer] = set()\n",
    "    influencer_to_restaurants[influencer].add(restaurant)\n",
    "    \n",
    "# build edges influencer\n",
    "# for every pair of influencers who reviewed the same restaurant, add an edge\n",
    "influencer_edges = {}\n",
    "for restaurant, influencers in restaurant_to_influencers.items():\n",
    "    if len(influencers) > 1:\n",
    "        for pair in itertools.combinations(sorted(influencers), 2):\n",
    "            influencer_edges[pair] = influencer_edges.get(pair, 0) + 1\n",
    "\n",
    "# build edges restaurant\n",
    "# for every pair of restaurants reviewed by the same influencer, add an edge\n",
    "restaurant_edges = {}\n",
    "for influencer, restaurants in influencer_to_restaurants.items():\n",
    "    if len(restaurants) > 1:\n",
    "        for pair in itertools.combinations(sorted(restaurants), 2):\n",
    "            restaurant_edges[pair] = restaurant_edges.get(pair, 0) + 1\n",
    "\n",
    "# Create DataFrames for influencer nodes and edges:\n",
    "\n",
    "df_influencer_nodes = pd.DataFrame({\n",
    "    \"Id\": list(influencer_nodes),\n",
    "    \"Label\": list(influencer_nodes),\n",
    "})\n",
    "\n",
    "# sort\n",
    "df_influencer_nodes = df_influencer_nodes.sort_values(\"Id\")\n",
    "\n",
    "# convert influencer edges\n",
    "influencer_edges_list = []\n",
    "for (source, target), weight in influencer_edges.items():\n",
    "    influencer_edges_list.append({\"Source\": source, \"Target\": target, \"Weight\": weight})\n",
    "\n",
    "# create DataFrame\n",
    "df_influencer_edges = pd.DataFrame(influencer_edges_list)\n",
    "\n",
    "# Create DataFrames for restaurant nodes and edges.\n",
    "df_restaurant_nodes = pd.DataFrame({\n",
    "    \"Id\": list(restaurant_nodes),\n",
    "    \"Label\": list(restaurant_nodes)\n",
    "})\n",
    "df_restaurant_nodes = df_restaurant_nodes.sort_values(\"Id\")\n",
    "\n",
    "restaurant_edges_list = []\n",
    "for (source, target), weight in restaurant_edges.items():\n",
    "    restaurant_edges_list.append({\"Source\": source, \"Target\": target, \"Weight\": weight})\n",
    "df_restaurant_edges = pd.DataFrame(restaurant_edges_list)\n",
    "\n",
    "# Save dataframes to the respective CSV files for Gephi\n",
    "df_influencer_nodes.to_csv(\"../gephi/influencer_nodes.csv\", index=False)\n",
    "df_influencer_edges.to_csv(\"../gephi/influencer_edges.csv\", index=False)\n",
    "df_restaurant_nodes.to_csv(\"../gephi/restaurant_nodes.csv\", index=False)\n",
    "df_restaurant_edges.to_csv(\"../gephi/restaurant_edges.csv\", index=False)\n",
    "\n",
    "print(\"CSV files created:\")\n",
    "print(\" - influencer_nodes.csv\")\n",
    "print(\" - influencer_edges.csv\")\n",
    "print(\" - restaurant_nodes.csv\")\n",
    "print(\" - restaurant_edges.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IG posts: 2753\n",
      "IG posts with ratingAvailable True: 536\n",
      "CSV files generated:\n",
      " - influencer_nodes_2.csv\n",
      " - influencer_edges_2.csv\n",
      " - restaurant_nodes_2.csv\n",
      " - restaurant_edges_2.csv\n"
     ]
    }
   ],
   "source": [
    "# compare review count, rating, and overall score (Yelp vs Instagram sentiment)\n",
    "# creating version 2 gephi files\n",
    "\n",
    "# Load restaurants CSV\n",
    "restaurants_df = pd.read_csv('../outputs/merged_restaurants_final.csv')\n",
    "# Normalize restaurant names in CSV for matching (case insensitive purposes)\n",
    "restaurants_df['norm_name'] = restaurants_df['name'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Load IG posts (with sentiments) JSON\n",
    "with open('../outputs/IG_posts_with_sentiment.json', 'r', encoding='utf-8') as f:\n",
    "    ig_posts = json.load(f)\n",
    "\n",
    "# Filter IG posts: only include those with ratingAvailable: true.\n",
    "# Normalize the restaurantName field.\n",
    "valid_posts = [\n",
    "    post for post in ig_posts \n",
    "    if post.get('ratingAvailable') is True and post.get('restaurantName', '').strip() != ''\n",
    "]\n",
    "\n",
    "# For all valid posts, create a normalized restaurant name.\n",
    "for post in valid_posts:\n",
    "    post['norm_restaurant'] = post.get('restaurantName', '').strip().lower()\n",
    "\n",
    "print(f\"Total IG posts: {len(ig_posts)}\")\n",
    "print(f\"IG posts with ratingAvailable True: {len(valid_posts)}\")\n",
    "\n",
    "\n",
    "# Create a dictionary mapping normalized restaurant name -> list of IG posts mentioning it\n",
    "posts_by_restaurant = {}\n",
    "for post in valid_posts:\n",
    "    norm_name = post['norm_restaurant']\n",
    "    posts_by_restaurant.setdefault(norm_name, []).append(post)\n",
    "\n",
    "# For each restaurant (normalized) compute:\n",
    "# - IG_overall_score: average overall_score from IG posts\n",
    "# - IG_review_count: number of IG posts for that restaurant\n",
    "ig_agg = {}\n",
    "for norm_name, posts in posts_by_restaurant.items():\n",
    "    scores = [\n",
    "        post.get(\"sentiment_analysis\", {}).get(\"overall_score\") \n",
    "        for post in posts if post.get(\"sentiment_analysis\", {}).get(\"overall_score\") is not None\n",
    "    ]\n",
    "    if scores:\n",
    "        avg_score = sum(scores) / len(scores)\n",
    "        ig_agg[norm_name] = {\n",
    "            'IG_overall_score': round(avg_score, 2),\n",
    "            'IG_review_count': len(scores)\n",
    "        }\n",
    "        \n",
    "# combine restaurant data from CSV and IG\n",
    "# Get the set of restaurants (by normalized name) from IG posts. These are the only ones we consider (around 500)\n",
    "ig_restaurants = set(posts_by_restaurant.keys())\n",
    "\n",
    "# Create a DataFrame for final restaurants.\n",
    "final_restaurants = pd.DataFrame({'norm_name': list(ig_restaurants)})\n",
    "\n",
    "# Merge the CSV info onto final_restaurants.\n",
    "# Left join final_restaurants with restaurants_df on norm_name.\n",
    "final_restaurants = final_restaurants.merge(\n",
    "    restaurants_df[['norm_name', 'name', 'borough', 'rating', 'review_count']],\n",
    "    on='norm_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge the aggregated IG data onto final_restaurants.\n",
    "final_restaurants = final_restaurants.merge(\n",
    "    pd.DataFrame.from_dict(ig_agg, orient='index').reset_index().rename(columns={'index': 'norm_name'}),\n",
    "    on='norm_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# For restaurants not present in CSV, fill missing CSV columns with NaN (or other defaults if you prefer).\n",
    "final_restaurants['name'] = final_restaurants['name'].fillna(final_restaurants['norm_name'])\n",
    "final_restaurants['borough'] = final_restaurants['borough'].fillna('Unknown')\n",
    "final_restaurants['rating'] = final_restaurants['rating'].fillna(np.nan)\n",
    "final_restaurants['review_count'] = final_restaurants['review_count'].fillna(0)\n",
    "\n",
    "# Compute a difference metric: for restaurants that have both a CSV rating and an IG overall score.\n",
    "final_restaurants['score_diff'] = final_restaurants.apply(\n",
    "    lambda row: row['IG_overall_score'] - row['rating'] if pd.notnull(row['rating']) and pd.notnull(row['IG_overall_score']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Attempt to use the original CSV \"name\" if available;\n",
    "# otherwise we use the normalized restaurant name.\n",
    "final_restaurants['Label'] = final_restaurants['name']\n",
    "# CONTINUE WITH UNIPARTITE APPROACH \n",
    "\n",
    "# Influencer Network\n",
    "# Nodes: unique influencers from valid_posts.\n",
    "influencer_set = set(post.get(\"influencerUsername\", \"\").strip() for post in valid_posts)\n",
    "influencer_nodes = pd.DataFrame({\"Id\": list(influencer_set), \"Label\": list(influencer_set)})\n",
    "\n",
    "# Influencer edges: edge between two influencers if they reviewed the same restaurant.\n",
    "influencer_edges = {}\n",
    "for norm_rest, posts in posts_by_restaurant.items():\n",
    "    influencers = sorted({ post.get(\"influencerUsername\", \"\").strip() for post in posts })\n",
    "    if len(influencers) > 1:\n",
    "        for pair in itertools.combinations(influencers, 2):\n",
    "            influencer_edges[pair] = influencer_edges.get(pair, 0) + 1\n",
    "\n",
    "influencer_edges_df = pd.DataFrame([\n",
    "    {\"Source\": pair[0], \"Target\": pair[1], \"Weight\": weight} \n",
    "    for pair, weight in influencer_edges.items()\n",
    "])\n",
    "\n",
    "\n",
    "# For restaurant edges:\n",
    "# each influencer is mapped to the set of normalized restaurants they reviewed.\n",
    "influencer_to_restaurants = {}\n",
    "for post in valid_posts:\n",
    "    influencer = post.get(\"influencerUsername\", \"\").strip()\n",
    "    norm_rest = post.get(\"norm_restaurant\", \"\")\n",
    "    if influencer and norm_rest:\n",
    "        influencer_to_restaurants.setdefault(influencer, set()).add(norm_rest)\n",
    "\n",
    "restaurant_edges = {}\n",
    "for influencer, rest_set in influencer_to_restaurants.items():\n",
    "    if len(rest_set) > 1:\n",
    "        for pair in itertools.combinations(sorted(rest_set), 2):\n",
    "            restaurant_edges[pair] = restaurant_edges.get(pair, 0) + 1\n",
    "\n",
    "# use a lookup dictionary to create the restaraunt edges for Gephi\n",
    "lookup = pd.Series(final_restaurants.Label.values, index=final_restaurants.norm_name).to_dict()\n",
    "restaurant_edges_df = pd.DataFrame([\n",
    "    {\"Source\": lookup.get(pair[0], pair[0]),\n",
    "     \"Target\": lookup.get(pair[1], pair[1]),\n",
    "     \"Weight\": weight}\n",
    "    for pair, weight in restaurant_edges.items()\n",
    "    if pair[0] in lookup and pair[1] in lookup\n",
    "])\n",
    "\n",
    "# output to csv files for use in gephi\n",
    "influencer_nodes.to_csv(\"../gephi/influencer_nodes_2.csv\", index=False)\n",
    "influencer_edges_df.to_csv(\"../gephi/influencer_edges_2.csv\", index=False)\n",
    "final_restaurants[['norm_name', 'Label', 'borough', 'rating', 'review_count', 'IG_overall_score', 'IG_review_count', 'score_diff']]\\\n",
    "    .rename(columns={'norm_name': 'Id'})\\\n",
    "    .to_csv(\"../gephi/restaurant_nodes_2.csv\", index=False)\n",
    "restaurant_edges_df.to_csv(\"../gephi/restaurant_edges_2.csv\", index=False)\n",
    "\n",
    "print(\"CSV files generated:\")\n",
    "print(\" - influencer_nodes_2.csv\")\n",
    "print(\" - influencer_edges_2.csv\")\n",
    "print(\" - restaurant_nodes_2.csv\")\n",
    "print(\" - restaurant_edges_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
